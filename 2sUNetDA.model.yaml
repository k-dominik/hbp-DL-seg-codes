name: Two Steam U-Net DA
description: Two Steam U-Net trained on brain vasculature segmentation data from Ludovico Silvestri's European Laboratory for Non-linear Spectroscopy (LENS). 
             Two Steam U-Net is used as the segmentation network that takes up the inputs from source and target domain, and generate the respective segmentation results at the output.
             Two Steam U-Net uses differet encoders to process inputs from source and target, and use a common decoder to generate the respective segmentation outputs.
             To train the network, cross entropy loss between the prediction and ground truth labels is used for the source data.
             For the target data, image reconstrcution constraints are enforced on the segmentation outputs. Furthermore, source domain images
             are translated into the target domain using an adverserial paradigm, to generate auxiliary labelled data for the target domain. 
             The labelled data thus generated are used to establish a supervised loss in the target domain.
cite:
    - text: "Roger Bermudez et al. A domain-adaptive two-stream U-Net for electron microscopy image segmentation. ISBI 2018."
      doi: https://doi.org/10.1109/ISBI.2018.8363602
authors:
  - Roger Bermudez, Vasu Subeesh
documentation: documentation/TransferLearningBasedSegmentationWorkflow.md
tags: [unet2d, pytorch, hbp, sga2, brain, vasculature]
license: MIT

format_version: 0.1.0
language: python
framework: pytorch

source: src.utils.get_2sunet
optional_kwargs:
    steps:                   4
    first_layer_channels:    64
    num_classes:             2
    num_input_channels:      3
    two_sublayers:           True
    ndims:                   2
    border_mode:             same
    remove_skip_connections: False
    layer_sharing_specification: r,r,s,s
    input_is_from_source_domain: False

test_input: tests/data/ipt10.npy
test_output: tests/data/2sunetda10.npy
covers: [documentation/covers/2sUNetCover.png]

inputs:
  - name: raw
    axes: bcyx
    data_type: float32
    data_range: [0, 1]
    shape: [1, 3, 512, 512]

outputs:
  - name: probs
    axes: bcyx
    data_type: float32
    data_range: [-inf, inf]
    halo: [0, 0, 94, 94]
    shape:
      reference_input: raw
      scale: [1, 1, 1, 1]
      offset: [0, 0, 0, 0]

prediction:
  preprocess:
    - spec: https://github.com/bioimage-io/pytorch-bioimage-io/blob/b44ff3b99fa2717dd0efea6932b6b07ea1a2b9af/specs/transformations/EnsureNumpy.transformation.yaml
    - spec: https://github.com/bioimage-io/python-bioimage-io/blob/b44ff3b99fa2717dd0efea6932b6b07ea1a2b9af/specs/transformations/NormalizeRange.transformation.yaml
      kwargs: {apply_to: 0, output_min: -1.0, output_max: 1.0}
    - spec: https://github.com/bioimage-io/pytorch-bioimage-io/blob/b44ff3b99fa2717dd0efea6932b6b07ea1a2b9af/specs/transformations/EnsureTorch.transformation.yaml
  weights:
      source: https://github.com/subeeshvasu/hbp-DL-seg-codes/releases/download/0.1.1/2sUNetDAweights.pth.tar
      hash: {sha256: 90d171979cbbef6bd5fb17e1829ef7141c0589ebae9a19bd8edf31a1bcac0bb3}
  postprocess:
    - spec: https://github.com/bioimage-io/pytorch-bioimage-io/blob/b44ff3b99fa2717dd0efea6932b6b07ea1a2b9af/specs/transformations/EnsureNumpy.transformation.yaml
  dependencies: conda:../environment.yaml
